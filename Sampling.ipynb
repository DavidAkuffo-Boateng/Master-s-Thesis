{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "wOyVeGi2qVYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust the path as necessary to point to your pickle file\n",
        "file_path = '/content/drive/My Drive/ITNPBD5 PROJECT/processed_empathetic_dialogues.pkl'\n",
        "\n",
        "# load the DataFrame\n",
        "with open(file_path, 'rb') as file:\n",
        "    processed_df = pickle.load(file)"
      ],
      "metadata": {
        "id": "L9d2pTX0rnhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verify the data\n",
        "print(f\"Loaded DataFrame shape: {processed_df.shape}\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(processed_df.head())\n",
        "print(\"\\nColumn names:\")\n",
        "print(processed_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-tTk5Z0zrzk2",
        "outputId": "4b641b47-aa5b-48f6-8e7b-3406388deb5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded DataFrame shape: (76497, 7)\n",
            "\n",
            "First few rows:\n",
            "       context                                             prompt  \\\n",
            "0       guilty  i felt guilty when i was driving home one nigh...   \n",
            "1       guilty  i felt guilty when i was driving home one nigh...   \n",
            "2       guilty  i felt guilty when i was driving home one nigh...   \n",
            "3       guilty  i felt guilty when i was driving home one nigh...   \n",
            "4  sentimental  i remember going to the fireworks with my best...   \n",
            "\n",
            "                                               input  \\\n",
            "0  yeah about 10 years ago i had a horrifying exp...   \n",
            "1  yeah about 10 years ago i had a horrifying exp...   \n",
            "2  yeah about 10 years ago i had a horrifying exp...   \n",
            "3  yeah about 10 years ago i had a horrifying exp...   \n",
            "4  i remember going to see the fireworks with my ...   \n",
            "\n",
            "                                              target       conv_id  \\\n",
            "0                       did you suffer any injuries?  hit:0_conv:0   \n",
            "1  no i wasn't hit. it turned out they were drunk...  hit:0_conv:0   \n",
            "2  why did you feel guilty? people really shouldn...  hit:0_conv:0   \n",
            "3  i don't know i was new to driving and hadn't e...  hit:0_conv:0   \n",
            "4  was this a friend you were in love with, or ju...  hit:0_conv:1   \n",
            "\n",
            "   utterance_idx  speaker_idx  \n",
            "0              2            1  \n",
            "1              3            0  \n",
            "2              4            1  \n",
            "3              5            0  \n",
            "4              2            0  \n",
            "\n",
            "Column names:\n",
            "Index(['context', 'prompt', 'input', 'target', 'conv_id', 'utterance_idx',\n",
            "       'speaker_idx'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We group the data by conv_id and context to get unique conversations per emotion. We then stratify sampling based on context to ensure representation from all emotion categories. and randomly select conversations within each emotion category. Then finally collect all utterances from the selected conversations until we reach about 1000 samples."
      ],
      "metadata": {
        "id": "iZ4P8e4RuHiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# group by conversation and get the first utterance of each (for emotion)\n",
        "conv_groups = processed_df.groupby('conv_id').first().reset_index()"
      ],
      "metadata": {
        "id": "NI64uq15uGfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the number of conversations to sample from each emotion\n",
        "emotion_counts = conv_groups['context'].value_counts()\n",
        "total_convs = len(conv_groups)\n",
        "sample_size = 1000\n",
        "prop_to_sample = sample_size / total_convs\n",
        "\n",
        "sampled_convs = []\n",
        "for emotion, count in emotion_counts.items():\n",
        "    n_sample = max(1, int(count * prop_to_sample))  # Ensure at least 1 sample per emotion\n",
        "    emotion_convs = conv_groups[conv_groups['context'] == emotion]\n",
        "    sampled_convs.extend(emotion_convs.sample(n=n_sample, random_state=42)['conv_id'].tolist())"
      ],
      "metadata": {
        "id": "qmAOEeXtuz5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all utterances from the sampled conversations\n",
        "sampled_df = processed_df[processed_df['conv_id'].isin(sampled_convs)]"
      ],
      "metadata": {
        "id": "oC0TbOKhu68s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if we have more than 1000 samples, randomly subsample to get closer to 1000\n",
        "if len(sampled_df) > 1000:\n",
        "    sampled_df = sampled_df.sample(n=1000, random_state=42)"
      ],
      "metadata": {
        "id": "_rvBiaM4vDJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Final sample size: {len(sampled_df)}\")\n",
        "print(\"\\nEmotion distribution in sample:\")\n",
        "print(sampled_df['context'].value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h06h4BvAvf0g",
        "outputId": "0de6d2af-bf99-4144-8787-e2af7a2cd21e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final sample size: 1000\n",
            "\n",
            "Emotion distribution in sample:\n",
            "context\n",
            "surprised       0.056\n",
            "guilty          0.040\n",
            "lonely          0.039\n",
            "proud           0.037\n",
            "embarrassed     0.036\n",
            "nostalgic       0.035\n",
            "joyful          0.034\n",
            "excited         0.034\n",
            "anxious         0.034\n",
            "sentimental     0.033\n",
            "content         0.033\n",
            "anticipating    0.033\n",
            "disgusted       0.032\n",
            "grateful        0.032\n",
            "annoyed         0.032\n",
            "caring          0.032\n",
            "jealous         0.031\n",
            "prepared        0.031\n",
            "terrified       0.030\n",
            "ashamed         0.029\n",
            "confident       0.029\n",
            "devastated      0.028\n",
            "furious         0.028\n",
            "impressed       0.028\n",
            "angry           0.028\n",
            "sad             0.027\n",
            "afraid          0.026\n",
            "trusting        0.026\n",
            "faithful        0.025\n",
            "disappointed    0.025\n",
            "hopeful         0.020\n",
            "apprehensive    0.017\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the sampled data\n",
        "sampled_df.to_csv('/content/drive/My Drive/ITNPBD5 PROJECT/sampled_empathetic_dialogues.csv', index=False)"
      ],
      "metadata": {
        "id": "-H0-2t-_vn14"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}